\documentclass[a4paper,12pt]{article} \usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} \usepackage[bulgarian]{babel} \usepackage{amsmath,
amssymb} \usepackage{listings} \usepackage{array,colortbl,xcolor}
\usepackage{ffcode} \usepackage{hyperref} \usepackage[margin=2.5cm]{geometry} %
Modify margins \usepackage{float} \geometry{margin=1in} \usepackage{graphicx}
\usepackage{booktabs} \usepackage[onehalfspacing]{setspace} % Increase line
spacing % Use natbib with superscript citations \usepackage[super]{natbib}
\hypersetup{ pdfborder={0 0 0}, colorlinks=true, urlcolor=blue, linkcolor=black,
citecolor=blue }

\author{Даниел Халачев} \title{WikiSearch} % \date{An optional custom date, the
default is today} \newcommand{\subtitle}{Търсачка над домейна bg.wikipedia.org}
\newcommand{\studentnumber}{4MI3400603} \newcommand{\program}{Извличане на
информация и откриване на знания} \newcommand{\supervisor}{проф. Иван Койчев}

\begin{document} \begin{titlepage} \makeatletter \begin{center}
\textsc{Софийски университет "Св. Климент Охридски"} \par \textsc{Факултет по
математика и информатика} \par Специалност "\program"

\vfill \hrule height .08em \bigskip \par\huge\@title\bigskip
\par\Large\subtitle\bigskip \hrule height .08em\normalsize \vfill
\includegraphics[width=\textwidth,height=0.25\textheight,keepaspectratio]{SU.
png} % The EUR logo, but this could also be another image \vfill
\begin{tabular}{ll} \toprule Изготвил: & \@author\\ Факултетен номер: &
\studentnumber\\ Преподавател: & \supervisor \\ Дата: & \@date\\ \bottomrule
\end{tabular} \vfill \end{center} \makeatother \end{titlepage} \newpage
\tableofcontents \newpage

\section*{Декларация за липса на плагиатство} \begin{itemize} \item Плагиатство
е да използваш, идеи, мнение или работа на друг, като претендираш, че са твои.
Това е форма на преписване. \end{itemize} \begin{itemize} \item Тази курсова
работа е моя, като всички изречения, илюстрации и програми от други хора са
изрично цитирани. \end{itemize} \begin{itemize} \item Тази курсова работа или
нейна версия не са представени в друг университет или друга учебна институция.
\end{itemize} \begin{itemize} \item Разбирам, че, ако се установи плагиатство в
работата ми, ще получа оценка “Слаб”. \end{itemize} \vspace{15cm}
\paragraph{Даниел Иванов Халачев} \newpage

\section{Увод}

\subsection{Лична мотивация} Да се приложат на практика част от теоретичните
познания, придобити от курсовете по \textit{Проектиране и обработка на естествен
език} и \textit{Изличане на информация}. Запознаване с езика за програмиране
Python чрез изграждане на напълно функционираща система.

\subsection{Техническа задача} Заданието цели изграждането на система, която да
удовлетворява едновременно изискванията за курсови проекти по дициплините
\emph{Извличане на информация} и \emph{Подходи за обработка на естествен език}.
Като такова, заданието има следните изисквания: \begin{itemize} \item Да се
създаде търсачка на уебсайтове с общо предназначение, която извършва търсенето
въз основа на два възможни подхода: \begin{itemize} \item семантично търсене
чрез document embeddings; \item традиционно търсене и ранкиране чрез TF-IDF и
BM25. \end{itemize} \item По възможност да се имплементират допълнителни
функционалности за подобряване на потребителското изживяване, като се използват
изградените индекси: \begin{itemize} \item кратки резюмета на резултатите от
търсенето \item предложения за корекции в правописа; \item предложения за
допълване на заявката за търсене; \item удобен графичен интерфейс. \end{itemize}
\item Да се оцени системата чрез обективни метрики. \end{itemize}
\subsection{Конректни задачи за изпълнение} \begin{table}[H] \centering
\begin{tabular}{|m{0.45\textwidth}|>{\color{gray}}m{0.45\textwidth}|} \hline
\textbf{Изличане на информация} & \textbf{Проектиране и обработка на EE} \\
\hline Изграждане на web crawler & Премахване на стоп думи, токенизация и
лематизация \\ \hline & Векторизация на документите \\ \hline Изграждане на
TF-IDF индекс & Изграждане на векторен индекс \\ \hline Имплементиране на
търсене и ранкиране на резултатите с BM25 & Имплементиране на търсене във
векторен индекс\\ \hline Допълване на заявката за търсене & \\ \hline Корекция
на правописа & \\ \hline Графичен интерфейс & \\ \hline
\multicolumn{2}{|c|}{Оценяване на системата}\\ \hline \end{tabular}
\caption{Конкретни задачи по дисциплините} \end{table} \section{Преглед на
областта} Търсенето и извличане на информация е проблем, който остава актуален с
експоненциалното разрастване на обема на съдържанието в интернет. Съвременните
търсачки с общо предназначение използват множество методи за подобряване на
релевантността на резултатите: \begin{itemize} \item лематизация на токените с
цел повишаване на откриването на семантични връзки между заявката и документите
в индекса \item TF-IDF индекс за нормализирана оценка на релевантността на
документите въз основа на броя срещания на токените в конкретен документ и във
всички документи като цяло \item откриване на именовани единици (\emph{Named
Entity Recognition}) и задаване на по-високи тегла на тези документи, в които
единиците присъстват \item допълнителни критерии за търсене въз основа на
потребителските метаданни - местоположение, език, предишни потребителски
търсения, данни от профили в други системи \item семантично търсене чрез
векторизация на документите и заявките (чрез езикови модели) и изчисляване на
косинусовата близост между тях \end{itemize} Поради липсата на метаданни за
потребителите и ограничени възможности за добиването и симулирането им, тази
система се концентрира върху два основни метода: \begin{itemize} \item TF-IDF
търсене и ранкиране чрез BM25 \item семантично търсене чрез векторизация.
\end{itemize} \newpage \section{Дизайн и архитектура на системата} Системата
може да бъде поделена на две части - \emph{backend} и \emph{frontend}.
\subsection{Backend} Системата предоставя своите услуги чрез \emph{REST API},
който по избор може да бъде консумиран от графичен интерфейс или външна система.
Интерфейсът съдържа следните входове и параметри (REST API endpoints):
\begin{itemize} \item \ff{/autocomplete} \begin{itemize} \item \ff{q} - низ за
допълване \end{itemize} \item \ff{/search} \begin{itemize} \item \ff{q} - низ на
заявката \item \ff{index} - тип на индекса за търсене, \ff{semantic} или
\ff{inverted} \item \ff{spellcheck} - да се извърши или не проверка на правописа,
по подразбиране \ff{true} \item \ff{limit} - брой върнати резултати (с цел
странициране) \item \ff{offset} - брой пропуснати резултати (с цел странициране)
\end{itemize} \end{itemize} Ползването на системата включва два етапа, които
могат да протекат последователно или паралелно: \begin{itemize} \item изграждане
на индексите \item търсене в индексите. \end{itemize} \paragraph{Изграждане на
индексите} Системата за търсене е проектирана така, че да поддържа добавяне и
изтриване на документи от индекса в реално време, дори по време на нейната
експлоатация. Изграждането на индекса преминава през следните етапи:
\begin{enumerate} \item \textbf{crawling} - извличане на текстовото съдържание
на страниците от специфичен домейн \item \textbf{лематизация} - премахване на
стоп думи, токенизация, определяне на основните форми на токените (леми) \item
\textbf{попълване} на индекса с така откритите леми. \end{enumerate} Системата
поддържа паралелно потоково изпълнение на тези етапи - извлечените документи се
поставят в опашка от задания. Всяко задание включва две действия - лематизация и
добавяне в индекса. По този начин скоростта на \emph{crwaling} не зависи от
скоростта на индексиране и обратно. В допълнение, системата поддържа и
итеративно поетапно изпълнение на тези етапи. Индексът, предвиден за
демонстрация на системата, беше създаден именно поетапно поради хардуерни
ограничения. \paragraph{Търсене в индексите} Търсенето в индекса преминава през
следните етапи: \begin{enumerate} \item \textbf{допълване на заявките} по време
на писането им \item \textbf{проверка на правописа} на изпратена заявка за
търсене \item \textbf{лематизация} - премахване на стоп думи, токенизация,
определяне на основните форми на токените в заявката \item \textbf{търсене в
TF-IDF индекса} и ранкиране чрез BM25 (едновременно) \item генериране на
\textbf{статични резюмета} за всеки документ \end{enumerate} Всички тези
дейности се извършват строго последователно. \subsection{Frontend} Графичният
интерфейс се състои от начална страница и страница за преглед на резултатите от
търсенето. В допълнение се предоставя и скрито меню за настройка на параметрите
на търсене: \begin{itemize} \item вид индекс - векторен или обратен \item вид
резюмета - статични или динамични (към този момент системата поддържа само
статични) \item брой резултати на страница \item изключване на правописната
проверка. \end{itemize} \newpage \section{Програмна реализация} Системата е
реализирана на езика \emph{Python}. Всеки вид обработка е обособен в модул,
които предоставя обекти, изпълними като услуги. Услугите са достъпни посредством
\emph{REST API}, изградено чрез библиотеката \emph{FastAPI}.
\subsection{Crawling} Изграден е \emph{crawling} модул, който поддържа
разнообразни параметри за всяка \emph{crawing} сесия: \begin{itemize} \item
домейн \item списък от начални адреси \item лимит на документите. \end{itemize}

Допълнително, crawling обектът поддържа списък на посетените адреси за
избягване на дубликати.

С цел избягване на ненужни заявки към сървъра на Wikipedia, първоначалното
изграждане на индексите се извърши чрез корпус от всички статии в българския
поддомейн на Уикипедия (\texttt{bg.wikipedia.org}). Целият корпус възлиза на
441\,385 документа, от които 302\,500 са статии, а останалите - пренасочващи
страници. Корпусът е достъпен от файла \texttt{bg-wiki-20250120-pages-articles.
xml.bz2}\cite{wiki}.

Разархивиран, той има размер от 3.0 GB и съдържа всички страници на
\\\texttt{bg.wikipedia.org} в WikiMarkup формат и техните метаданни,
организирани йерархично в XML дърво. С цел поетапна многостъпкова обработка,
бяха извлечени само данните на страниците на статии, след което бяха преработени
до чист текст, съхранен в бърза и скалируема база данни - \emph{LMDB}\cite{lmdb}.

\subsection{Лематизация} Премахването на стоп думи, токенизацията и
лематизацията са предмет на заданието по дисциплината \emph{Проектиране и
обработка на естествен език}, но детайлите са споменати тук за пълнота, защото
от този етап зависи качеството на TF-IDF индекса. Тези обработки бяха
осъществени чрез библиотеката \texttt{spacy} и модела
\texttt{sakelariev/bg-news-lg}\cite{sakelariev_bg_news_lg}.

\subsection{Изграждане на TF-IDF индекс} Традиционно TF-IDF индексите се
изграждат като дървета във файлова система, работеща на \emph{Solid State Drive}.
Тъй като системата се изпълнява на \emph{Hard Disk Drive}, традиционната схема
би забавила значително системата поради латентността на входно-изходните
операции. Затова индексът е съхранен в \emph{MySQL} релационна база данни, която
позволява преодоляване на латентността, интелигентно кеширане на най-честите
търсения и ефективно откъм памет съхранение, без необходимост от задържане на
целия индекс в работната памет.

\subsection{Търсене и ранкиране} С цел максимална бързина на търсенето, на един
етап се извършва едновременно определянето на релевантните документи и техния
ранг в крайните резултати чрез групирани \emph{SQL} транзакции. Използват се
метриките TF-IDF и BM25.

\subsection{Допълване на заявките за търсене} Допълване на заявките за търсене
(\emph{Query Autocompletion}) позволява на потребителя да получи предложения за
търсене въз основа на вече написана част от заявка. За максимална ефективност бе
използвана структурата от данни \emph{насочен ацикличен граф за думи}
(\emph{Directed Acyclic Word Graph - DAWG}). Този вид графи съхранява общите
части на низовете си само веднъж. Всеки възел наследник действа като добавя
суфикс (наставка, продължение) към изградената до текущия възел дума. За нуждите
на системата се изграждат два DAWG графа: \begin{itemize} \item първият граф
допълва една единствена дума; \item вторият граф допълва фрази. Това се постига
чрез съхраняване на всички срещнати в индекса словосъчетания като низове във
формат "дума1 дума2". \end{itemize} Търсенето в тези структури е с изчислителна
сложност $O(n)$. \subsection{Корекция на правописа} Корекцията на правописа е
реализирана като услуга, изградена върху речник на български за библиотеката
$Hunspell$, но се поддържа и речник, генериран изключително само от думите в
TF-IDF индекса. \subsection{Оценяване} Първоначалната идея за оценяване на
системата върху целия домейн \texttt{bg.wikipedia.org} вече не беше приложима
поради неочаквано бавното изграждане на векторния индекс.

Затова за демонстрация, че индексът работи, бяха избрани 1000 произволни статии,
които да бъдат добавени съответно във векторния и обратния индекс. За златен
стандарт беше избрана библиотеката ElasticSearch, която е с доказана репутация и
ефективност в областта. Беше създаден специален модул за генериране на заявки за
търсене и оценка на резултатите. Могат да бъдат генерирани групи заявки от два
вида с произволен брой и разпределение на всеки вид в групата: \begin{itemize}
\item заглавие на произволен документ \item избор на най-често срещаните
колокации от две думи в произволни документи. Колокациите трябва да се срещат
поне 3 пъти в текста. \end{itemize}

\section{Резултати} Резултатите от WikiSearch бяха сравнени с резултатите на
ElasticSearch по критериите Precision, Recall и F1. За целта бяха създадени 5
групи от по 30 заявки за търсене, които очакват до 20 резултата. За всяка заявка
се изчисляват Precision, Recall и F1. Чрез тях се изчисляват средните стойности
на тези показатели за всяка група. Оценителят връща окончателен резултат
95\%-доверителен интервал за всяка метрика Precision, Recall, F1, изчислен чрез
всички 5 групи. По този начин се гарантира представителност на статистическата
извадка, защото са изпълнени условията за прилагането на Централна гранична
теорема.

\begin{table}[h] \centering \begin{tabular}{|c|c|c|} \hline Precision & Recall
& F1 \\ \hline $0.870\pm0.034$ & $0.893\pm0.030$& $0.877\pm0.030$ \\ \hline
\end{tabular} \caption{Резултати на WikiSearch за обратния индекс} \end{table}
Постигнатите резултати, показани в таблицата по-горе, са високи и доказват
успешната реализация на системата.

\section{Заключение. Възможности за бъдещо подобрение} Така създадената система
гарантира добро потребителско изживяване и високо качество на търсенето (поне с
TF-IDF индекс). В допълнение, нейната архитектура позволява промяна и
надграждане на индекса по време на експлоатация. Предоставянето на услугите под
формата на Rest API позволява използване на търсачката от потребители, графични
интерфейси и други приложения. Въпреки това са възможни разнообразни подобрения:
\begin{itemize} \item Изграждане на индекс върху целия домейн \texttt{bg.
wikipedia.org} и сравнение на резултатите с тези, върнати от Wikipedia, а не от
ElasticSearch\footnote{Това би било съпроводено с други проблеми в оценяването,
защото Wikipedia подобрява резултатите от търсенето чрез графи на знанието.};
\item Подобряване на семантичното търсене чрез Избор на по-подходящ модел за
векторизация на текстовете, предназначен специално за български език; \item
обединение на двата вида търсене (чрез обратен и векторен индекс) в един вид
търсене, който съчетава прециозността на TF-IDF с откриването на семантични
връзки чрез векторния индекс, дори при липса на ключови думи \item Интелигентно
резюмиране на резултатите; \item предложения за допълване на заявките и корекция
на правописа въз основа на историята на потребителските търсения, а не само на
речника на индекса; \item обогатяване на търсенето чрез използване на
потребителски метаданни; \item по-голямо бързойдействие чрез по-фина
паралелизация; \item поддръжка на разпределена база данни чрез sharding и др.
\end{itemize} \section{Код} Кодът се съхранява в хранилище на адрес \url{https:
//github.com/DanielHalachev/WikiSearch}. \begin{thebibliography}{9}
\bibitem{wiki} BgWiki Dumps, \textit{Wikimedia Foundation}, \url{https://dumps.
wikimedia.org/bgwiki/20250120/bgwiki-20250120-pages-articles.xml.bz2}.

\bibitem{sakelariev_bg_news_lg} sakelariev/bg-news-lg, \textit{HuggingFace},
\url{https://huggingface.co/sakelariev/bg_news_lg}

\bibitem{lmdb} LMDB: Lightning Memory Database, \textit{Symas}, \url{http://www.
lmdb.tech/doc/} \end{thebibliography} \end{document}